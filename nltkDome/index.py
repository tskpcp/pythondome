from nltk.tokenize import word_tokenize
if __name__=='__main__':
    sentence='hello word'
    tokens=word_tokenize(sentence)
    print(tokens)
